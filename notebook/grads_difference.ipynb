{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fda917-c878-42ca-9b19-ddb453fd989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from fedlab.utils.serialization import SerializationTool\n",
    "from fedlab.utils.aggregator import Aggregators\n",
    "from fedlab.utils.functional import evaluate\n",
    "\n",
    "# 将项目根目录加入环境变量\n",
    "PROJECT_DIR = os.path.dirname(os.getcwd())\n",
    "sys.path.append(PROJECT_DIR)\n",
    "\n",
    "from data.CIFAR10.partition import partition_example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d32aea65",
   "metadata": {},
   "source": [
    "## 前期准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型结构\n",
    "class CNN_CIFAR10(nn.Module):\n",
    "    \"\"\"from torch tutorial\n",
    "        https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR10,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常规参数\n",
    "num_client = 50\n",
    "num_cluster = 10\n",
    "num_shards = 50\n",
    "num_classes = 10\n",
    "batch_size = 64\n",
    "global_model_file_dir = os.path.join(PROJECT_DIR, \"result\", \"models\", \"notebook\", \"grads_difference\")\n",
    "if not os.path.exists(global_model_file_dir):\n",
    "    os.makedirs(global_model_file_dir)\n",
    "global_model_file_name = \"global_model.pth\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"training device: \", device)\n",
    "\n",
    "# 数据加载\n",
    "partitioner = partition_example()\n",
    "\n",
    "testset = CIFAR10(root=partitioner.root, train=False, download=False, transform=partitioner.transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# 训练模型和全局模型\n",
    "client_models = [CNN_CIFAR10() for _ in range(num_client)]\n",
    "client_optimizers = [torch.optim.SGD(client_model.parameters(), lr=0.001) for client_model in client_models]\n",
    "client_criteria = [nn.CrossEntropyLoss() for _ in range(num_client)]\n",
    "\n",
    "if os.path.exists(os.path.join(global_model_file_dir, global_model_file_name)):\n",
    "    global_model = torch.load(os.path.join(global_model_file_dir, global_model_file_name))\n",
    "else:\n",
    "    global_model = CNN_CIFAR10()\n",
    "global_criteria = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e9b0d47",
   "metadata": {},
   "source": [
    "## 联邦模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c883555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本地模型训练\n",
    "def train(client_id, dataloader, grads_compute=False):\n",
    "    \"\"\"训练模型并返回梯度\n",
    "    该方法开始前, 本地模型(stored in client_models)已经被全局模型更新过一次.\n",
    "    因此, 直接使用本地模型进行训练即可.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # 准备当前训练的模型, 优化器和损失函数\n",
    "    current_client_model = client_models[client_id]\n",
    "    current_client_optimizer = client_optimizers[client_id]\n",
    "    current_client_criterion = client_criteria[client_id]\n",
    "    \n",
    "    # train local model\n",
    "    current_client_model.to(device)\n",
    "    for _ in range(5):\n",
    "        current_client_model.train()\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            current_client_optimizer.zero_grad()\n",
    "            outputs = current_client_model(inputs)\n",
    "            loss = current_client_criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            current_client_optimizer.step()\n",
    "    \n",
    "    # compute grads\n",
    "    if grads_compute:\n",
    "        # 使用 from fedlab.utils.serialization import SerializationTool 计算梯度\n",
    "        param_before_tensor = SerializationTool.serialize_model(global_model)\n",
    "        param_after_tensor = SerializationTool.serialize_model(current_client_model)\n",
    "        grads_tensor = param_after_tensor - param_before_tensor\n",
    "        \n",
    "        return grads_tensor\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15c205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局模型训练\n",
    "def global_train(num_rounds, freq_eval=20, freq_grads=50):\n",
    "    \"\"\"全局训练\n",
    "\n",
    "    Args:\n",
    "        num_rounds (int): 全局训练轮数\n",
    "        freq_eval (int, optional): 评估全局模型的频率. Defaults to 20.\n",
    "        freq_grads (int, optional): 统计client梯度的频率. Defaults to 50.\n",
    "    \n",
    "    Returns:\n",
    "        client_grads (dict): client梯度的字典\n",
    "    \"\"\"\n",
    "    # 准备存储client梯度的字典\n",
    "    client_grads = {i: [] for i in range(num_client)}\n",
    "    \n",
    "    # 全局训练\n",
    "    for round in range(num_rounds):\n",
    "        # 每轮开始前, 将本地模型的参数更新为全局模型的参数\n",
    "        for client_model in client_models:\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "        \n",
    "        # train local model and get grads\n",
    "        for client_id in range(num_client):\n",
    "            train_loader = partitioner.get_dataloader(client_id, batch_size)\n",
    "            \n",
    "            if round % freq_grads == 0:\n",
    "                grads = train(client_id, train_loader, grads_compute=True)\n",
    "                client_grads[client_id].append(grads)\n",
    "            else:\n",
    "                grads = train(client_id, train_loader, grads_compute=False)\n",
    "            \n",
    "\n",
    "        # update global model\n",
    "        client_parameters = [\n",
    "            SerializationTool.serialize_model(client_model) for client_model in client_models\n",
    "        ]\n",
    "        SerializationTool.deserialize_model(\n",
    "            global_model, Aggregators.fedavg_aggregate(client_parameters)\n",
    "        )\n",
    "        \n",
    "        if round % freq_eval == 0:\n",
    "            loss, acc = evaluate(global_model, global_criteria, test_loader)\n",
    "            print(f\"Round {round} finished, loss: {loss}, acc: {acc}\")\n",
    "    \n",
    "    return client_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动全局训练\n",
    "global_model.to(device)\n",
    "client_grads = global_train(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696221e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存全局模型\n",
    "torch.save(global_model, os.path.join(global_model_file_dir, global_model_file_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17a3a7e9",
   "metadata": {},
   "source": [
    "## 计算梯度方向相似性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69155792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算余弦相似性\n",
    "def cosine_matrix(vectors):\n",
    "    \n",
    "    grads_np = [np.array(grad) for grad in vectors]\n",
    "    cosine_similarity = np.zeros((len(vectors), len(vectors)))\n",
    "    for i in range(len(vectors)):\n",
    "        for j in range(len(vectors)):\n",
    "            cosine_similarity[i][j] = np.dot(grads_np[i].flatten(), grads_np[j].flatten()) / (np.linalg.norm(grads_np[i]) * np.linalg.norm(grads_np[j]))\n",
    "            cosine_similarity[j][i] = cosine_similarity[i][j]\n",
    "\n",
    "    return cosine_similarity\n",
    "\n",
    "# 绘制余弦相似性矩阵的热点图\n",
    "def plot_similarity_matrix(similarity_matrix):\n",
    "    plt.imshow(similarity_matrix, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbabb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 client_grads 的余弦相似性矩阵\n",
    "cosine_similarity_matrixs = []\n",
    "for i in range(len(client_grads[0])):\n",
    "    grads_vectors = [client_grads[j][i] for j in range(num_client)] # 统计相同轮次的梯度\n",
    "    cosine_similarity = cosine_matrix(grads_vectors)\n",
    "    cosine_similarity_matrixs.append(cosine_similarity)\n",
    "\n",
    "# 随机选择一个轮次, 绘制其余弦相似性矩阵\n",
    "random_round = np.random.randint(0, len(cosine_similarity_matrixs))\n",
    "print(f\"random round: {random_round}\")\n",
    "plot_similarity_matrix(cosine_similarity_matrixs[random_round])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06124a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制所有轮次的余弦相似性矩阵\n",
    "for i in range(len(cosine_similarity_matrixs)):\n",
    "    plot_similarity_matrix(cosine_similarity_matrixs[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2666c288",
   "metadata": {},
   "source": [
    "## 比较数据标签分布的相似性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个client的标签分布, 即计算每个client中每个标签的比例\n",
    "client_labels_matrix = [[] for _ in range(num_client)]\n",
    "for client_id in range(num_client):\n",
    "    client_dataset = partitioner.get_dataset(client_id)\n",
    "    client_labels = client_dataset.y\n",
    "    labels_total = len(client_labels)\n",
    "    labels_counter = Counter(client_labels)\n",
    "    for i in range(10):\n",
    "        if i not in labels_counter:\n",
    "            labels_counter[i] = 0\n",
    "    for _, v in sorted(labels_counter.items()):\n",
    "        client_labels_matrix[client_id].append(v/labels_total)\n",
    "\n",
    "    print(f\"client {client_id} labels distribution: {client_labels_matrix[client_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262e8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 client_labels_matrix 的余弦相似性矩阵\n",
    "client_labels_similarity_matrix = cosine_matrix(client_labels_matrix)\n",
    "print(client_labels_similarity_matrix)\n",
    "\n",
    "# 绘制 client_labels_similarity_matrix 的热点图\n",
    "plot_similarity_matrix(client_labels_similarity_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
