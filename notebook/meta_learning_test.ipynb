{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比较两种Per-Fedavg算法实现\n",
    "1. 基于梯度实现的方式\n",
    "    \n",
    "    https://github.com/KarhouTam/Per-FedAvg\n",
    "2. 基于 pytorch 的实现方式\n",
    "\n",
    "    https://github.com/KarhouTam/FL-bench/blob/master/src/client/perfedavg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple, Union\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from fedlab.utils.serialization import SerializationTool\n",
    "from fedlab.utils.aggregator import Aggregators\n",
    "from fedlab.utils.functional import evaluate\n",
    "\n",
    "# 将项目根目录加入环境变量\n",
    "PROJECT_DIR = os.path.dirname(os.getcwd())\n",
    "sys.path.append(PROJECT_DIR)\n",
    "print(PROJECT_DIR)\n",
    "\n",
    "from utils import read_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config, cluster_partitioner, model = read_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_client = config['num_client']\n",
    "num_classes = config['num_classes']\n",
    "num_round = config['num_round']\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "client_sample_stream = [\n",
    "    random.sample(\n",
    "        range(num_client), max(1, int(num_client * 0.2))\n",
    "    )\n",
    "    for _ in range(num_round)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_init():\n",
    "    client_trainloaders: List[DataLoader] = [cluster_partitioner.get_dataloader(cid, config['local_bs']) for cid in range(num_client)]\n",
    "    client_iter_trainloaders: List[Tuple[DataLoader]] = [iter(client_trainloaders[i]) for i in range(num_client)]\n",
    "\n",
    "    client_testloaders: List[DataLoader] = [cluster_partitioner.get_dataloader(cid, config['local_bs'], type=\"test\") for cid in range(num_client)]\n",
    "\n",
    "    return client_trainloaders, client_iter_trainloaders, client_testloaders\n",
    "\n",
    "def model_init():\n",
    "    client_models: List[torch.nn.Module] = [model() for _ in range(num_client)]\n",
    "    client_optimizers: List[torch.optim.SGD] = [torch.optim.SGD(client_models[i].parameters(), lr=config['lr']) for i in range(num_client)]\n",
    "    client_criterion: List[torch.nn.CrossEntropyLoss] = [torch.nn.CrossEntropyLoss() for _ in range(num_client)]\n",
    "\n",
    "    global_model: torch.nn.Module = model()\n",
    "    global_optimizer: torch.optim.SGD = torch.optim.SGD(global_model.parameters(), lr=config['lr'])\n",
    "    global_criterion: torch.nn.CrossEntropyLoss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    return client_models, client_optimizers, client_criterion, \\\n",
    "        global_model, global_optimizer, global_criterion\n",
    "\n",
    "def get_data_batch(cid, client_trainloaders, client_iter_trainloaders):\n",
    "    try:\n",
    "        x, y = next(client_iter_trainloaders[cid])\n",
    "    except StopIteration:\n",
    "        client_iter_trainloaders[cid] = iter(client_trainloaders[cid])\n",
    "        x, y = next(client_iter_trainloaders[cid])\n",
    "\n",
    "    return x.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_trainloaders, client_iter_trainloaders, client_testloaders = dataloader_init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于梯度计算的实现方式\n",
    "https://github.com/KarhouTam/Per-FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad(\n",
    "    compute_model: torch.nn.Module,\n",
    "    data_batch: Tuple[torch.Tensor, torch.Tensor],\n",
    "    v: Union[Tuple[torch.Tensor, ...], None] = None,\n",
    "    second_order_grads=False,\n",
    "    criterion: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n",
    "):\n",
    "    x, y = data_batch\n",
    "    if second_order_grads:\n",
    "        frz_model_params = deepcopy(compute_model.state_dict())\n",
    "        delta = 1e-3\n",
    "        dummy_model_params_1 = OrderedDict()\n",
    "        dummy_model_params_2 = OrderedDict()\n",
    "        with torch.no_grad():\n",
    "            for (layer_name, param), grad in zip(compute_model.named_parameters(), v):\n",
    "                dummy_model_params_1.update({layer_name: param + delta * grad})\n",
    "                dummy_model_params_2.update({layer_name: param - delta * grad})\n",
    "\n",
    "        compute_model.load_state_dict(dummy_model_params_1, strict=False)\n",
    "        logit_1 = compute_model(x)\n",
    "        loss_1 = criterion(logit_1, y)\n",
    "        grads_1 = torch.autograd.grad(loss_1, compute_model.parameters())\n",
    "\n",
    "        compute_model.load_state_dict(dummy_model_params_2, strict=False)\n",
    "        logit_2 = compute_model(x)\n",
    "        loss_2 = criterion(logit_2, y)\n",
    "        grads_2 = torch.autograd.grad(loss_2, compute_model.parameters())\n",
    "\n",
    "        compute_model.load_state_dict(frz_model_params)\n",
    "\n",
    "        grads = []\n",
    "        with torch.no_grad():\n",
    "            for g1, g2 in zip(grads_1, grads_2):\n",
    "                grads.append((g1 - g2) / (2 * delta))\n",
    "        return grads\n",
    "\n",
    "    else:\n",
    "        logit = compute_model(x)\n",
    "        loss = criterion(logit, y)\n",
    "        grads = torch.autograd.grad(loss, compute_model.parameters())\n",
    "        return grads\n",
    "\n",
    "def perfedavg_1_train(cid, client_model, client_trainloaders, client_iter_trainloaders, hessian_free=True):\n",
    "    if hessian_free:\n",
    "        for _ in range(config['local_ep']):\n",
    "            for _ in range(len(client_trainloaders[cid]) // 3):\n",
    "                temp_model = deepcopy(client_model)\n",
    "                data_batch_1 = get_data_batch(cid, client_trainloaders, client_iter_trainloaders)\n",
    "                grads = compute_grad(temp_model, data_batch_1)\n",
    "                for param, grad in zip(temp_model.parameters(), grads):\n",
    "                    param.data.sub_(config['per_alpha'] * grad)\n",
    "\n",
    "                data_batch_2 = get_data_batch(cid, client_trainloaders, client_iter_trainloaders)\n",
    "                grads_1st = compute_grad(temp_model, data_batch_2)\n",
    "\n",
    "                data_batch_3 = get_data_batch(cid, client_trainloaders, client_iter_trainloaders)\n",
    "\n",
    "                grads_2nd = compute_grad(\n",
    "                    client_model, data_batch_3, v=grads_1st, second_order_grads=True\n",
    "                )\n",
    "                # NOTE: Go check https://github.com/KarhouTam/Per-FedAvg/issues/2 if you confuse about the model update.\n",
    "                for param, grad1, grad2 in zip(\n",
    "                    client_model.parameters(), grads_1st, grads_2nd\n",
    "                ):\n",
    "                    param.data.sub_(config['per_beta'] * grad1 - config['per_beta'] * config['per_alpha'] * grad2)\n",
    "    else:\n",
    "        for _ in range(config['local_ep']):\n",
    "            for _ in range(len(client_trainloaders[cid]) // 2):\n",
    "                temp_model = deepcopy(client_model)\n",
    "                data_batch_1 = get_data_batch(cid, client_trainloaders, client_iter_trainloaders)\n",
    "                grads = compute_grad(temp_model, data_batch_1)\n",
    "\n",
    "                for param, grad in zip(temp_model.parameters(), grads):\n",
    "                    param.data.sub_(config['per_alpha'] * grad)\n",
    "\n",
    "                data_batch_2 = get_data_batch(cid, client_trainloaders, client_iter_trainloaders)\n",
    "                grads = compute_grad(temp_model, data_batch_2)\n",
    "\n",
    "                for param, grad in zip(client_model.parameters(), grads):\n",
    "                    param.data.sub_(config['per_beta'] * grad)\n",
    "\n",
    "def pers_eval(cid, client_model, client_trainloaders, client_iter_trainloaders, eval_loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    loss_before, acc_before = evaluate(client_model, criterion, eval_loader)\n",
    "    optimizer = torch.optim.SGD(client_model.parameters(), lr=config['per_alpha'])\n",
    "    for _ in range(config['pers_epoch']):\n",
    "        for _ in range(len(client_trainloaders[cid]) // 3):\n",
    "            x, y = get_data_batch(cid, client_trainloaders, client_iter_trainloaders)\n",
    "            logit = client_model(x)\n",
    "            loss = criterion(logit, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    loss_after, acc_after = evaluate(client_model, criterion, eval_loader)\n",
    "    # print(\"client [{}] [red]loss: {:.4f} -> {:.4f}   [blue]acc: {:.2f}% -> {:.2f}%\".format(\n",
    "    #     cid, loss_before, loss_after, acc_before * 100.0, acc_after * 100.0\n",
    "    # ))\n",
    "    return loss_before, loss_after, acc_before, acc_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_models, _, _, global_model, _, _ = model_init()\n",
    "\n",
    "for current_round in range(num_round):\n",
    "    selected_client_ids = client_sample_stream[current_round]\n",
    "    if current_round % 2 == 0:\n",
    "        model_params_cache = []\n",
    "        for cid in selected_client_ids:\n",
    "            local_model = client_models[cid]\n",
    "            local_model.load_state_dict(global_model.state_dict())\n",
    "            local_model.to(device)\n",
    "            perfedavg_1_train(cid, local_model, client_trainloaders, client_iter_trainloaders, hessian_free=True)\n",
    "            model_params_cache.append(SerializationTool.serialize_model(local_model))\n",
    "        aggregated_model_params = Aggregators.fedavg_aggregate(model_params_cache)\n",
    "        SerializationTool.deserialize_model(global_model, aggregated_model_params)\n",
    "    else:\n",
    "        all_loss_before, all_loss_after, all_acc_before, all_acc_after = 0.0, 0.0, 0.0, 0.0\n",
    "        for cid in selected_client_ids:\n",
    "            local_model = client_models[cid]\n",
    "            local_model.load_state_dict(global_model.state_dict())\n",
    "            local_model.to(device)\n",
    "            eval_loader = client_testloaders[cid]\n",
    "            loss_before, loss_after, acc_before, acc_after = pers_eval(cid, local_model, client_trainloaders, client_iter_trainloaders, eval_loader)\n",
    "            all_loss_before += loss_before\n",
    "            all_loss_after += loss_after\n",
    "            all_acc_before += acc_before\n",
    "            all_acc_after += acc_after\n",
    "        all_loss_before /= len(selected_client_ids)\n",
    "        all_loss_after /= len(selected_client_ids)\n",
    "        all_acc_before /= len(selected_client_ids)\n",
    "        all_acc_after /= len(selected_client_ids)\n",
    "        print(\"round:{}, client {}, loss: {:.4f} -> {:.4f},  acc: {:.2f}% -> {:.2f}%\".format(\n",
    "            current_round, selected_client_ids, all_loss_before, all_loss_after, all_acc_before * 100.0, all_acc_after * 100.0\n",
    "        ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 pytorch 实现的方案\n",
    "https://github.com/KarhouTam/FL-bench/blob/master/src/client/perfedavg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfedavg_2_train(cid, client_model, criterion, optimizer, client_trainloaders, client_iter_trainloaders, hessian_free=True):\n",
    "    client_model.train()\n",
    "    meta_optimizer = torch.optim.SGD(client_model.parameters(), lr=config['per_beta'])\n",
    "    model_plus = deepcopy(client_model)\n",
    "    model_minus = deepcopy(client_model)\n",
    "    delta = 1e-3\n",
    "    for _ in range(config['local_ep']):\n",
    "        for _ in range(len(client_trainloaders[cid]) // (2 + hessian_free)):\n",
    "            x0, y0 = get_data_batch(cid, client_trainloaders, client_iter_trainloaders)\n",
    "            frz_model = deepcopy(client_model)\n",
    "            logit = client_model(x0)\n",
    "            loss = criterion(logit, y0)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            x1, y1 = get_data_batch(cid, client_trainloaders, client_iter_trainloaders)\n",
    "            logit = client_model(x1)\n",
    "            loss = criterion(logit, y1)\n",
    "            meta_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            if hessian_free:\n",
    "                model_plus.load_state_dict(frz_model.state_dict())\n",
    "                model_minus.load_state_dict(frz_model.state_dict())\n",
    "\n",
    "                x2, y2 = get_data_batch(cid, client_trainloaders, client_iter_trainloaders)\n",
    "\n",
    "                for param_p, param_m, param_cur in zip(model_plus.parameters(), model_minus.parameters(), client_model.parameters()):\n",
    "                    param_p.data += delta * param_cur.grad\n",
    "                    param_m.data -= delta * param_cur.grad\n",
    "                \n",
    "                logit_plus = model_plus(x2)\n",
    "                logit_minus = model_minus(x2)\n",
    "\n",
    "                loss_plus = criterion(logit_plus, y2)\n",
    "                loss_minus = criterion(logit_minus, y2)\n",
    "\n",
    "                loss_plus.backward()\n",
    "                loss_minus.backward()\n",
    "\n",
    "                for param_p, param_m, param_cur in zip(model_plus.parameters(), model_minus.parameters(), client_model.parameters()):\n",
    "                    param_cur.grad = param_cur.grad - config['lr'] / (2 * delta) * (param_p.grad - param_m.grad)\n",
    "                    param_p.grad.zero_()\n",
    "                    param_m.grad.zero_()\n",
    "            \n",
    "            client_model.load_state_dict(frz_model.state_dict())\n",
    "            meta_optimizer.step()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_models, client_optimizers, client_criterions, global_model, _, _ = model_init()\n",
    "\n",
    "for current_round in range(num_round):\n",
    "    selected_client_ids = client_sample_stream[current_round]\n",
    "    if current_round % 2 == 0:\n",
    "        model_params_cache = []\n",
    "        for cid in selected_client_ids:\n",
    "            local_model = client_models[cid]\n",
    "            local_model.load_state_dict(global_model.state_dict())\n",
    "            local_optimizer = client_optimizers[cid]\n",
    "            local_criterion = client_criterions[cid]\n",
    "            local_model.to(device)\n",
    "            perfedavg_2_train(cid, local_model, local_criterion, local_optimizer, client_trainloaders, client_iter_trainloaders)\n",
    "            model_params_cache.append(SerializationTool.serialize_model(local_model))\n",
    "        aggregated_model_params = Aggregators.fedavg_aggregate(model_params_cache)\n",
    "        SerializationTool.deserialize_model(global_model, aggregated_model_params)\n",
    "    else:\n",
    "        all_loss_before, all_loss_after, all_acc_before, all_acc_after = 0.0, 0.0, 0.0, 0.0\n",
    "        for cid in selected_client_ids:\n",
    "            local_model = client_models[cid]\n",
    "            local_model.load_state_dict(global_model.state_dict())\n",
    "            local_model.to(device)\n",
    "            eval_loader = client_testloaders[cid]\n",
    "            loss_before, loss_after, acc_before, acc_after = pers_eval(cid, local_model, client_trainloaders, client_iter_trainloaders, eval_loader)\n",
    "            all_loss_before += loss_before\n",
    "            all_loss_after += loss_after\n",
    "            all_acc_before += acc_before\n",
    "            all_acc_after += acc_after\n",
    "        all_loss_before /= len(selected_client_ids)\n",
    "        all_loss_after /= len(selected_client_ids)\n",
    "        all_acc_before /= len(selected_client_ids)\n",
    "        all_acc_after /= len(selected_client_ids)\n",
    "        print(\"round:{}, client {}, loss: {:.4f} -> {:.4f},  acc: {:.2f}% -> {:.2f}%\".format(\n",
    "            current_round, selected_client_ids, all_loss_before, all_loss_after, all_acc_before * 100.0, all_acc_after * 100.0\n",
    "        ))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
